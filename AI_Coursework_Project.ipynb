{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LhtZHNJd3psC"
   },
   "source": [
    "# AI Coursework Project\n",
    "\n",
    "#### **Table of Contents**\n",
    "\n",
    "-  **Section 1: Generating the Dataset**\n",
    "- **Section 2: Encoder Decoder**\n",
    "- **Section 3: AutoEncoder**\n",
    "- **Section 4: Functions class: containing all functions used in encoder, decoder and training**\n",
    "- **Section 5: Initializing The Model & Training**\n",
    "- **Section 6: Plotting the results**\n",
    "- **Section 7: Testing the model(Using pickle test data)**\n",
    "\n",
    "Below you can find the code generating the data according to different random sinusoidal functions $\\{f_a\\}$. We randomly generate a set of 40 points in the x-axis in the interval $[-2, 2]$, slightly randomly shifted. Our functions will have the form of $y = f_a(x) = a * sin(x+a)$ where each $a$ will be randomly sampled for each function from interval $[-2, 2]$. \n",
    "\n",
    "## 1. Generating the Dataset\n",
    "\n",
    "I have redesigned the provided code such that it is embedded in a Gen_Dataset class. not only will this make it work with the dataloader, but will allow us to generate a test dataset to try."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Q0gl9f3K-LNu",
    "outputId": "9bd85ecc-738b-4072-a1a5-fcfb43becd8b"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'google.colab'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-58f05add940d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/gdrive'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'google.colab'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from itertools import chain\n",
    "import random\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive', force_remount=True)\n",
    "import sys\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class Gen_Dataset(Dataset):\n",
    "    \"\"\"\n",
    "    Generating Dataset Class\n",
    "\n",
    "    This class uses the provided data generation functions.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, n_functions):\n",
    "        # Sinosodial function\n",
    "        Nf = n_functions\n",
    "        Npts = 40\n",
    "        self.x = torch.zeros(Nf, Npts, 1)\n",
    "        for k in range(Nf):\n",
    "            self.x[k, :, 0] = torch.linspace(-2, 2, Npts)\n",
    "        self.x += torch.rand_like(self.x) * 0.1\n",
    "        a = -2 + 4 * torch.rand(Nf).view(-1, 1).repeat(1, Npts).unsqueeze(2)\n",
    "        self.y = a * torch.sin(self.x + a)\n",
    "        self.n_samples = self.x.shape[0]\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # Slicing Method\n",
    "        return self.x[index], self.y[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        # len method\n",
    "        return self.n_samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hvi_67FQ4kLR"
   },
   "source": [
    "## 2. Encoder Decoder\n",
    "Below is the code used for the encoder and decoder. they are initialized in the autoencoder such that I only use 1 model for the optimizer and during training. \n",
    "\n",
    " - Output size for the encoder is rDim.\n",
    " - Input size of decoder is rDim + 1, which is the output of rDim + xt column.\n",
    " - Output size for the decoder is hard-coded to 1, which is ypred.\n",
    " - only 2 hidden layers used in this MLP Encoder Decoder Model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "v_iXxHQNpOMZ"
   },
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    \"\"\"\n",
    "    Encoder\n",
    "\n",
    "    Takes as input Xc and Yc context pairs, passes the context pairs through network,\n",
    "    applying some activation function resulting in rc. Mean function applied\n",
    "    to rc and rC is returned.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, inputSize, hiddenSize, rDim):\n",
    "        super(Encoder, self).__init__()\n",
    "\n",
    "        # Initialising parameters\n",
    "        self.outputSize = rDim\n",
    "\n",
    "        # Hidden Layers\n",
    "        self.Layer1 = nn.Linear(inputSize, hiddenSize)\n",
    "        self.ReLU = nn.ReLU()\n",
    "        self.Layer2 = nn.Linear(hiddenSize, self.outputSize)\n",
    "\n",
    "    def forward(self, contextPairs):\n",
    "        # Layer 1 > relu > layer 2 > mean > out\n",
    "        rc = self.ReLU(self.Layer1(contextPairs))\n",
    "        rc = self.Layer2(rc)\n",
    "        rC = torch.mean(rc, dim=1)\n",
    "        return rC\n",
    "\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    \"\"\"\n",
    "    Decoder\n",
    "\n",
    "    Takes as input rC and Xt, passes the inputs through network,\n",
    "    applying some activation function resulting in y_hat. y_hat is\n",
    "    returned\n",
    "    \"\"\"\n",
    "    def __init__(self, hiddenSize, rDim):\n",
    "        super(Decoder, self).__init__()\n",
    "\n",
    "        # Initialising parameters\n",
    "        self.outputSize = 1\n",
    "\n",
    "        # Hidden Layers\n",
    "        self.Layer1 = nn.Linear(rDim + 1, hiddenSize)\n",
    "        self.ReLU = nn.ReLU()\n",
    "        self.Layer2 = nn.Linear(hiddenSize, self.outputSize)\n",
    "\n",
    "    def forward(self, decoderInput):\n",
    "        # layer1 > relu > layer 2 > output\n",
    "        decoderInput = self.ReLU(self.Layer1(decoderInput))\n",
    "        ypred = self.Layer2(decoderInput)\n",
    "\n",
    "        return ypred\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TLoppRUg47Sw"
   },
   "source": [
    "## 3. AutoEncoder\n",
    "The autoencoder combines the Encoder and Decoder. I initialize the AutoEncoder with the parameters required by the encoder and decoder. \n",
    "\n",
    " - The if statements in the forward part of the encoder relate to how I did my test plots:\n",
    "  - All inputs in the forward method of this class are initialised with some value.\n",
    "  - If encoderOnly == true, context pairs are passed through xt and the values are sent to the encoder only, returning rC.\n",
    "  - If decoderOnly == true, decoder inputs are passed through xt and the values are sent to the decoder only, returning ypred.\n",
    "  - Formatting functions are only operated in the autoencoder, to keep the encoder and decoder as simple as possible. All methods used can be found in the Functions class found below this block."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0JfgbtUqpS3F"
   },
   "outputs": [],
   "source": [
    "class AutoEncoder(nn.Module):\n",
    "    def __init__(self, inputSize, hiddenSize, rDim):\n",
    "      super(AutoEncoder, self).__init__()\n",
    "\n",
    "      # Initializing rDim, inputSize / hiddenSize only needed in encoder / decoder\n",
    "      self.rDim = rDim\n",
    "\n",
    "      # Initializing encoder / decoder\n",
    "      self.encoder = Encoder(inputSize, hiddenSize, rDim)\n",
    "      self.decoder = Decoder(hiddenSize, rDim)\n",
    "\n",
    "    def forward(self, xt=None, yt=None, encoderOnly=False, decoderOnly=False):\n",
    "      # If statements only true when using test data, otherwise works as normal\n",
    "      if encoderOnly==True:\n",
    "        rC = self.encoder(xt)\n",
    "        return rC\n",
    "      if decoderOnly==True:\n",
    "        y_hat = self.decoder(xt)\n",
    "        return y_hat\n",
    "\n",
    "      # Taking in xtyt of batch and concatenating\n",
    "      x = torch.cat((xt, yt), dim=2)\n",
    "\n",
    "      # Getting context pairs and passing to the encoder\n",
    "      contextPairs = Functions.get_context(self, x)\n",
    "      rC = self.encoder(contextPairs)\n",
    "\n",
    "      # Formatting xt rC and passing it to decoder\n",
    "      x = Functions.format_input(self, xt, rC)\n",
    "      ypred = self.decoder(x)\n",
    "\n",
    "      # Returning prediction\n",
    "      return ypred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Kl1guS3P4_Sv"
   },
   "source": [
    "## 4. Functions class: containing all functions used in encoder, decoder and training\n",
    " - **get context** method formats the xc and yc pairs. firstly selecting nc number of pairs, and creating a list of indices. The list is then used to select context pairs from each function. Each batch will have the same number of Nc values, but different batches will have different numbers of context pairs.\n",
    "- min Nc = 5\n",
    "- max Nc = 35\n",
    "- randomly selected indeces\n",
    "\n",
    " - **format_input** method takes rc and xt to combine them into an appropriate format for the decoder\n",
    "\n",
    " - **Train** method contains the training loop, which outputs the loss at each epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EP994SzEpXBI"
   },
   "outputs": [],
   "source": [
    "class Functions(AutoEncoder):\n",
    "    def __init__(self):\n",
    "        super(Functions, self).__init__()\n",
    "\n",
    "    def get_context(self, batchIn):\n",
    "        \"\"\"\n",
    "        Firstly creating an empty list, then randomly selecting a number between 5 and 35 which will be the\n",
    "        number of context pairs. This is then passed into a for loop, for each selected index, select the\n",
    "        context pair located at that index, and append it to the context pairs tensor.\n",
    "\n",
    "        Tensor then split into xc and yc values.\n",
    "\n",
    "        :param batchIn: takes the batch in, used for indexing and accessing xt / yt pairs\n",
    "        :return: chosen xc, yc values as well as both formatted as pairs\n",
    "        \"\"\"\n",
    "        global xc, yc\n",
    "\n",
    "        # selection list, this will be the index list used to select pairs at random.\n",
    "        selection = []\n",
    "\n",
    "        self.batchSizeIn = batchIn.shape[0]\n",
    "\n",
    "        # Randomization: min of 5 context pairs and max of 35\n",
    "        n = random.randint(5, 35)\n",
    "        for i in range(0, n):\n",
    "            #index ranges between 0-39, so any of the 40 examples from a function can be selected\n",
    "            n = random.randint(0, 39)\n",
    "            selection.append(n)\n",
    "\n",
    "        # Empty 3D tensor to hold the context pairs.\n",
    "        contextPairs = torch.empty(0, len(selection), 2)\n",
    "\n",
    "        # for each batch, then for each function, select context pairs and append to contextPairs tensor\n",
    "        for batch in range(0, self.batchSizeIn):\n",
    "            context = None\n",
    "            for index in selection:\n",
    "                c = batchIn[batch, index, :]\n",
    "                if context is None:\n",
    "                    context = c.unsqueeze(1)\n",
    "                else:\n",
    "                    context = torch.cat((context, c.unsqueeze(1)), dim=1)\n",
    "\n",
    "            context = context.T\n",
    "            contextPairs = torch.cat((contextPairs, context.unsqueeze(0)), dim=0)\n",
    "        xc, yc = contextPairs[:, :, :1], contextPairs[:, :, 1:2]\n",
    "\n",
    "        return contextPairs\n",
    "\n",
    "    def format_input(self, xtIn, rCIn):\n",
    "        \"\"\"\n",
    "        Formats xt and rC into an appropriate input to pass into the decoder.\n",
    "        :param xtIn: xt values in, tensor will always be [batchsize, 40, 1]\n",
    "        :param rCIn: rC values in, tensor will always be [batchsize, rDim]\n",
    "        :return: formatted input appropriate for decoder\n",
    "        \"\"\"\n",
    "        #Adding a dimension to rC, then combining rC and xt\n",
    "        rCIn = rCIn.unsqueeze(1)\n",
    "        decoderInput = torch.cat((xtIn, rCIn.expand(self.batchSizeIn, 40, self.rDim)), dim=2)\n",
    "\n",
    "        return decoderInput\n",
    "\n",
    "    def train(num_epochs, dataloader, criterion, optimizer, model):\n",
    "        \"\"\"\n",
    "        Trains the model on the functions and context pairs extracted from\n",
    "        the dataloader\n",
    "        :param dataloader: the iterable dataloader\n",
    "        :param criterion: the loss function to use\n",
    "        :param optimizer: Adam or SGD\n",
    "        :param model: pass in the AutoEncoder\n",
    "        :return: predictions\n",
    "        \"\"\"\n",
    "        #Training Loop\n",
    "        print('Beginning to train...\\n')\n",
    "        global xt, yt\n",
    "        for epoch in range(num_epochs):\n",
    "            for (xt, yt) in dataloader:\n",
    "              xt, yt = xt, yt\n",
    "              y_hat = model(xt, yt)\n",
    "              loss = criterion(y_hat, yt)\n",
    "              optimizer.zero_grad()\n",
    "              loss.backward()\n",
    "              optimizer.step()\n",
    "\n",
    "            print(f'Epoch:\\t{epoch + 1}/{num_epochs}\\t\\tLoss:\\t{loss.item():4f}')\n",
    "\n",
    "        print('\\nTraining Complete.')\n",
    "        return y_hat\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PULc9sA85atK"
   },
   "source": [
    "## 5 Initializing The Model & Training\n",
    "All hyperparameters listed at the top.\n",
    "\n",
    " - dataloader generates 2000 functions\n",
    " - autoencoder (2 MLPS (Encoder and Decoder)) initialized\n",
    " - Loss criterion initialized (MSE)\n",
    " - Optimizer Initialized (adam or SGD)\n",
    "\n",
    "\n",
    "Training loop is performed by passing in all appropriate inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DWpVJ4A4-MX7",
    "outputId": "dcdb77e0-345a-4531-ce4d-cec7876713fc"
   },
   "outputs": [],
   "source": [
    "# Setting batch size\n",
    "batchSize = 20\n",
    "learning_rate = 0.001\n",
    "weight_decay = 0.00005\n",
    "hiddenSize = 30\n",
    "rDim = 3\n",
    "num_epochs = 75\n",
    "\n",
    "# Generating Dataset (Training Data and Test Data)\n",
    "trainData = Gen_Dataset(2000)\n",
    "\n",
    "# Dataloader\n",
    "trainLoader = DataLoader(dataset=trainData, batch_size=batchSize, shuffle=True, num_workers=2)\n",
    "\n",
    "#Model Initialization\n",
    "autoencoder = AutoEncoder(inputSize=2, hiddenSize=hiddenSize, rDim=rDim)\n",
    "\n",
    "# Loss Criterion Used\n",
    "meanSquaredError = nn.MSELoss()\n",
    "\n",
    "# Optimizers\n",
    "optimizer = torch.optim.Adam(autoencoder.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "#optimizer = torch.optim.SGD(autoencoder.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "\n",
    "# Training\n",
    "ypred = Functions.train(num_epochs=num_epochs,\n",
    "                dataloader=trainLoader,\n",
    "                criterion=meanSquaredError,\n",
    "                optimizer=optimizer,\n",
    "                model=autoencoder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xGA9Zz365tvR"
   },
   "source": [
    "## 6. Plotting the results\n",
    "\n",
    "Firstly, the plot below shows how well the model performs on explicitly the last function in the batch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 682
    },
    "id": "1NtIymKq-jDW",
    "outputId": "0404119f-d0b6-4b4d-a508-b298f46e01dc"
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize = (15,10))\n",
    "\n",
    "ax.set_facecolor('whitesmoke')\n",
    "plt.plot(xt[0,:,0].to('cpu'), yt[0,:,0].to('cpu'), color = 'cornflowerblue', \n",
    "         linewidth = 2, label = 'Function Pairs (xt, yt)')\n",
    "plt.plot(xc[0,:,0].to('cpu'), yc[0,:,0].to('cpu'), '*', color='orange',\n",
    "         label='Context Pairs (xc, yc)')\n",
    "plt.plot(xt[0,:,0].to('cpu'), ypred[0,:,0].detach().to('cpu'), \n",
    "         color = 'darkseagreen', linewidth = 2, label = 'Model Predictions')\n",
    "plt.suptitle('Model Evaluation (Performed on last batch)', fontsize = 25)\n",
    "plt.xlabel('X Function Inputs', fontsize = 15)\n",
    "plt.ylabel('Outputs From Sinosodial Functions', fontsize = 15)\n",
    "plt.legend(fontsize = 12)\n",
    "plt.grid(alpha = 0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-kfgQRpZ5xar"
   },
   "source": [
    "## 7. Testing the model (Using Pickle test data)\n",
    "I have defined one method which does 3 main things:\n",
    " - extract each functions' context pairs and xt values.\n",
    " - Processes them through our model, previously trained in previous sections.\n",
    " - Plots the models predictions against the context pairs provided."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "ixkg9vo2l1FA"
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/content/gdrive/MyDrive/Colab Notebooks/test_data.pkl'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-c9a400bab59c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mpath_to_the_pickle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/content/gdrive/MyDrive/Colab Notebooks/test_data.pkl'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtest_data\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_to_the_pickle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_prediction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/gdrive/MyDrive/Colab Notebooks/test_data.pkl'"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "path_to_the_pickle = '/content/gdrive/MyDrive/Colab Notebooks/test_data.pkl'\n",
    "test_data =pickle.load(open(path_to_the_pickle,'rb'))\n",
    "\n",
    "def get_prediction(function):\n",
    "  # 6 test functions\n",
    "  name= 'function_num_{}'.format(function)\n",
    "  xc=test_data[name]['context_pairs'][0]\n",
    "  yc=test_data[name]['context_pairs'][1]\n",
    "  xt=test_data[name]['x']\n",
    "\n",
    "  testContext = torch.cat((xc, yc), dim=2)\n",
    "  rCtest = autoencoder(xt=testContext, encoderOnly=True)\n",
    "\n",
    "  rCtest = rCtest.unsqueeze(1)\n",
    "  rCtest.expand(1, xc.shape[1], -1)\n",
    "  decoderInput = torch.cat((xt, rCtest.expand(1, xt.shape[1], -1)), dim=2)\n",
    "\n",
    "  ypred = autoencoder(xt=decoderInput, decoderOnly=True)\n",
    "\n",
    "  fig, ax = plt.subplots(figsize = (8,6))\n",
    "  ax.set_facecolor('whitesmoke')\n",
    "  plt.plot(xc[0,:,0].to('cpu'), yc[0,:,0].to('cpu'), '*', color='orange',\n",
    "         label='Test Context Pairs (xc, yc)')\n",
    "  plt.plot(xt[0,:,0].to('cpu'), ypred[0,:,0].detach().to('cpu'), \n",
    "         color = 'darkseagreen', linewidth = 2, label = 'Model Predictions')\n",
    "  plt.suptitle(f'Model Evaluation Against Test Function {function}', fontsize = 20)\n",
    "  plt.xlabel('X Function Inputs', fontsize = 12)\n",
    "  plt.ylabel('Outputs From Sinosodial Functions', fontsize = 12)\n",
    "  plt.legend(fontsize = 12)\n",
    "  plt.grid(alpha = 0.2)\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 434
    },
    "id": "AKKn1VPIQia0",
    "outputId": "55969f1d-0481-43fc-b079-a8abe5e79acb"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'get_prediction' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-9c8d393c9a26>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_prediction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'get_prediction' is not defined"
     ]
    }
   ],
   "source": [
    "get_prediction(function=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 434
    },
    "id": "55CwmqKvUoX4",
    "outputId": "ea352384-82ed-49cc-c390-3054c04a9f42"
   },
   "outputs": [],
   "source": [
    "get_prediction(function=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 434
    },
    "id": "weWPqScYVBJF",
    "outputId": "b7ef72e8-d9db-4110-f9b0-40c37e04b49d"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'get_prediction' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-a5c47bb3d345>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_prediction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'get_prediction' is not defined"
     ]
    }
   ],
   "source": [
    "get_prediction(function=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 434
    },
    "id": "3h1CyFOeVdse",
    "outputId": "5ac1348f-5c7c-4a21-fc4e-f5e546b3cba7"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'get_prediction' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-ced95899aec5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_prediction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'get_prediction' is not defined"
     ]
    }
   ],
   "source": [
    "get_prediction(function=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 434
    },
    "id": "dmYnQRgcVkeZ",
    "outputId": "1c9c4c7e-2133-4bf4-ce0b-6d6b37298d37"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'get_prediction' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-1b462ed62ec7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_prediction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'get_prediction' is not defined"
     ]
    }
   ],
   "source": [
    "get_prediction(function=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 434
    },
    "id": "bo7jSswDVneO",
    "outputId": "9e4b4630-18d3-40f4-aa06-07240df06b30"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'get_prediction' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-2ca3c22e3fcd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_prediction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'get_prediction' is not defined"
     ]
    }
   ],
   "source": [
    "get_prediction(function=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 539,
   "metadata": {
    "id": "buYjtESMxmdG"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "AI Coursework Project.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
